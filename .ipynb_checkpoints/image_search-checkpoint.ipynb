{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install scikit-learn\n",
    "# install from: http://docs.python-requests.org/en/master/\n",
    "# to fix ssl installation of python packages issue\n",
    "# curl https://bootstrap.pypa.io/get-pip.py | python3\n",
    "# instructions to setup virtualenv\n",
    "# https://www.tensorflow.org/install/install_mac\n",
    "# pip3 install -r requirements.txt\n",
    "\n",
    "import requests\n",
    "import cv2\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn.model_selection as model\n",
    "import tensorflow\n",
    "from csv import DictReader\n",
    "from urllib.request import urlopen\n",
    "from matplotlib.pyplot import imshow\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_x = []\n",
    "dataset_y = []\n",
    "\n",
    "spamreader = csv.DictReader(open(\"./datasets/jcpenney_com-ecommerce_sample.csv\"))\n",
    "for row in spamreader:\n",
    "    if (row[\"name_title\"] != \"\" and row[\"product_image_urls\"] != \"\"):\n",
    "#         response = requests.get(row[\"product_image_urls\"], stream = False)\n",
    "        dataset_x.append(row[\"product_image_urls\"])\n",
    "        dataset_y.append(row[\"name_title\"])\n",
    "    \n",
    "X = np.array(dataset_x)\n",
    "y = np.array(dataset_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model.train_test_split(X, y, test_size = 0.3)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 24 * 24])\n",
    "y = tf.placeholder(tf.float32, [None, len(X)])\n",
    "W1 = tf.Variable(tf.random_normal([5, 5, 1, 64]))\n",
    "b1 = tf.Variable(tf.random_normal([64]))\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 64, 64]))\n",
    "b2 = tf.Variable(tf.random_normal([64]))\n",
    "W3 = tf.Variable(tf.random_normal([6*6*64, 1024]))\n",
    "b3 = tf.Variable(tf.random_normal([1024]))\n",
    "W_out = tf.Variable(tf.random_normal([1024, len(X)]))\n",
    "b_out = tf.Variable(tf.random_normal([len(X)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(x, W, b):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv_with_b = tf.nn.bias_add(conv, b)\n",
    "    conv_out = tf.nn.relu(conv_with_b)\n",
    "    return conv_out\n",
    "\n",
    "def maxpool_layer(conv, k=2):\n",
    "    return tf.nn.max_pool(conv, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=\"SAME\")\n",
    "\n",
    "def model(): \n",
    "    x_reshaped = tf.reshape(x, shape=[-1, 24, 24, 1])\n",
    "\n",
    "    conv_out1 = conv_layer(x_reshaped, W1, b1)\n",
    "    maxpool_out1 = maxpool_layer(conv_out1)\n",
    "    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    conv_out2 = conv_layer(norm1, W2, b2)\n",
    "    norm2 = tf.nn.lrn(conv_out2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    maxpool_out2 = maxpool_layer(norm2)\n",
    "\n",
    "    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.get_shape().as_list()[0]])\n",
    "    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)\n",
    "    local_out = tf.nn.relu(local)\n",
    "\n",
    "    out = tf.add(tf.matmul(local_out, W_out), b_out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-ef1eea35635f>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_model = model()\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=image_model, labels=y)\n",
    ")\n",
    "\n",
    "# train the model trying to minimize the cost\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# measure the predicter\n",
    "correct_pred = tf.equal(tf.argmax(image_model), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'indices' has DataType float32 not in list of allowed values: uint8, int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d54c185a8f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0monehot_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moff_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0monehot_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[1;32m   2426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,\n\u001b[0;32m-> 2428\u001b[0;31m                                  name)\n\u001b[0m\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, name)\u001b[0m\n\u001b[1;32m   4440\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4441\u001b[0m         \u001b[0;34m\"OneHot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4442\u001b[0;31m         off_value=off_value, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   4443\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4444\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[1;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                                        param_name=input_name)\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[0;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;34m\"allowed values: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[0;32m---> 60\u001b[0;31m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: uint8, int32, int64"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    onehot_labels = tf.one_hot(y, len(X), on_value=1., off_value=0., axis=-1)\n",
    "    onehot_vals = sess.run(onehot_labels)\n",
    "    batch_size = len(dataset_x)\n",
    "    print(\"batch size \", batch_size)\n",
    "    for j in range(0, 1000):\n",
    "        avg_accuracy_val = 0.\n",
    "        batch_count = 0.\n",
    "        \n",
    "        for i in range(0, len(dataset_x), batch_size):\n",
    "            batch_data = dataset_x[i:i+batch_size, :]\n",
    "            batch_onehot_vals = onehot_vals[i:i+batch_size, :]\n",
    "            _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: batch_data, y: batch_onehot_vals})\n",
    "            avg_accuracy_val += accuracy_val\n",
    "            batch_count += 1.\n",
    "        \n",
    "        avg_accuracy_val /= batch_count\n",
    "        print(\"Epoch {}. Avg accuracy {}\".format(j, avg_accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
